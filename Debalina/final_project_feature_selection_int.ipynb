{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w261 Final Project - Clickthrough Rate Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your team number (from the spreadsheet)]   \n",
    "[Your team names]   \n",
    "Summer 2019, section [Your section numbers>]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* __Section 1__ - Question Formulation\n",
    "* __Section 2__ - Algorithm Explanation\n",
    "* __Section 3__ - EDA & Challenges\n",
    "* __Section 4__ - Algorithm Implementation\n",
    "* __Section 5__ - Course Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 1__ - Question Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 2__ - Algorithm Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 3__ - EDA & Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 4__ - Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 5__ - Course Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Initiate Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "from numpy import allclose\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import  RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler, VectorSlicer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session (RUN THIS CELL AS IS)\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"hw3_notebook\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.id', 'local-1564709664252'),\n",
       " ('spark.app.name', 'hw3_notebook'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.port', '39571'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.host', 'docker.w261')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark configuration Information (RUN THIS CELL AS IS)\n",
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Path and read in raw data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the toy data file\n",
    "toy_raw = ast.literal_eval(open(\"data/toy.txt\", \"r\").read())\n",
    "\n",
    "# Read the 10K sample data file for feature extraction and data preparation\n",
    "tenK_raw = ast.literal_eval(open(\"data/eda.txt\", \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 10K sample data file for feature extraction and data preparation\n",
    "# f = open(\"data/eda.txt\", \"r\")\n",
    "# eda = ast.literal_eval(f.read())\n",
    "# f.close()\n",
    "\n",
    "# # parse each row and return in list form\n",
    "# parsed_eda = sc.parallelize(eda).map(lambda x: x.split('\\t')).collect()\n",
    "# print(\"EDA row count:\", len(parsed_eda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Row Into Readable formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_row(row):\n",
    "    '''\n",
    "    for each row in the raw data,  output is a list of label and all the features:\n",
    "        - [label, feature_1, feature_1, ...]\n",
    "    For first 13 features, change the data type to number.\n",
    "    Remaining features will of type string.\n",
    "    For null values, populate None\n",
    "    '''\n",
    "    row_values = row.split('\\t')\n",
    "    for i, value in enumerate(row_values):\n",
    "        if i <14:\n",
    "            row_values[i] = int(value) if value != '' else None\n",
    "        else:\n",
    "            row_values[i] = value if value != '' else \"''\"\n",
    "    return row_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse raw toy data to form toyRDD\n",
    "toyRDD = sc.parallelize(toy_raw).map(parse_raw_row).cache()\n",
    "#toyRDD.take(1)\n",
    "\n",
    "# parse raw 10k sample data to form tenKRDD\n",
    "tenKRDD = sc.parallelize(tenK_raw).map(parse_raw_row).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe for Feature Engineering ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create SQL dataframe from RDD\n",
    "\n",
    "# for toy data\n",
    "toyFeature_df = sqlContext.createDataFrame(toyRDD)\n",
    "\n",
    "# for 10K sample data\n",
    "tenKfeature_df = sqlContext.createDataFrame(tenKRDD)\n",
    "#tenKfeature_df.dtypes\n",
    "\n",
    "# tenKfeature_df = df.withColumnRenamed(\"_1\", \"label\")\n",
    "#                    .withColumnRenamed(\"_2\", \"f1\")\n",
    "#                    .withColumnRenamed(\"_2\", \"f2\")\n",
    "#                    .withColumnRenamed(\"_2\", \"f3\")\n",
    "#                    .withColumnRenamed(\"_2\", \"f4\")\n",
    "#                    .withColumnRenamed(\"_2\", \"f5\")\n",
    "#                 .withColumnRenamed(\"_2\", \"f6\")\n",
    "#                    .withColumnRenamed(\"_2\", \"f7\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f8\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f9\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f10\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f11\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f12\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f13\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f14\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f15\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f16\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f17\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f18\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f19\")\n",
    "#                      .withColumnRenamed(\"_2\", \"f20\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f21\")\n",
    "#                      .withColumnRenamed(\"_2\", \"f22\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f23\")  \n",
    "#                     .withColumnRenamed(\"_2\", \"f24\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f25\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f26\")\n",
    "#                     .withColumnRenamed(\"_2\", \"f27\")\n",
    "#                                         .withColumnRenamed(\"_2\", \"f28\")\n",
    "#                                          .withColumnRenamed(\"_2\", \"f29\")\n",
    "#                                              .withColumnRenamed(\"_2\", \"f30\")\n",
    "#                                          .withColumnRenamed(\"_2\", \"f31\")\n",
    "#                                     .withColumnRenamed(\"_2\", \"f32\")\n",
    "#                                         .withColumnRenamed(\"_2\", \"f33\")\n",
    "#                                          .withColumnRenamed(\"_2\", \"f34\")\n",
    "#                                                      .withColumnRenamed(\"_2\", \"f35\")\n",
    "#                                                     .withColumnRenamed(\"_2\", \"f36\")                  \n",
    "#                                                     .withColumnRenamed(\"_2\", \"f37\")\n",
    "#                                                              .withColumnRenamed(\"_39\", \"f38\")\n",
    "#                                          .withColumnRenamed(\"_40\", \"f39\")\n",
    "                                                                                                                                                    \n",
    "\n",
    "\n",
    "\n",
    "#### Create Panda dataframe from RDD\n",
    "# create pandas dataframe\n",
    "# tenKfeature_df.toPandas() \n",
    "\n",
    "# features = ['label'] + list(range(1, 40))\n",
    "# tenKpanda_df = pd.DataFrame(tenKRDD, columns = features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1: Remove features with very large number of unknown data**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From EDA we see that the below feature columns have more than 40% null values.  \n",
    "Due to this high percenage of unknown data we won't keep these features in our model. So dropping these columns from our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| _1| _3| _4| _5| _6| _7| _8| _9|_10|_12|_14|     _15|     _16|     _17|     _18|     _19|     _20|     _21|     _22|     _23|     _24|     _25|     _26|     _27|     _28|     _29|     _30|     _31|     _32|     _35|     _37|     _38|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|  0|  6|  3| 34|  4| 27|  3| 33| 34|  1| 15|05db9164|028bd518|77f2f2e5|d16679b9|25c83c98|fbad5c96|2ecb612f|5b392875|a73ee510|3b08e48b|4efc1873|9f32b866|f15f3681|b28479f6|9559bea6|31ca40b6|07c540c4|2a40f0da|dfcfc3fa|32c7478e|aee52b6f|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop features with high unknown values\n",
    "\n",
    "toy_df1 = toyFeature_df.drop('_13','_36','_2','_11','_33','_34','_39','_40')\n",
    "tenK_df1 = tenKfeature_df.drop('_13','_36','_2','_11','_33','_34','_39','_40')\n",
    "\n",
    "tenK_df1.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Remove Categorical features with high % of Uniqueness of Categories**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From EDA, we see that for the following categorical features uniqueness is more than 50%. When uniqueness of a feature is more than 50% it should not be having much impact on label prediction. So will remove those columns from our model.  \n",
    "_17, _18, _21, _24, _26, _30, _35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| _1| _3| _4| _5| _6| _7| _8| _9|_10|_12|_14|     _15|     _16|     _19|     _20|     _22|     _23|     _25|     _27|     _28|     _29|     _31|     _32|     _37|     _38|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|  0|  6|  3| 34|  4| 27|  3| 33| 34|  1| 15|05db9164|028bd518|25c83c98|fbad5c96|5b392875|a73ee510|4efc1873|f15f3681|b28479f6|9559bea6|07c540c4|2a40f0da|32c7478e|aee52b6f|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toy_df2 = toy_df1.drop('_17','_18','_21','_24','_26','_30','_35')\n",
    "tenK_df2 = tenK_df1.drop('_17','_18','_21','_24','_26','_30','_35')\n",
    "tenK_df2.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Colenearity Reduction**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA shows strong correlation between below numerical features:  \n",
    "> _5 and _14  \n",
    "> _5 and _9  \n",
    "> _9 and _14  \n",
    "> _8 and _12  \n",
    "There is also a moderate negative correlation for feature:  \n",
    "> _6 and _11  \n",
    "> _7 and _11.  \n",
    "To avoid co-leniarity we will remove feature _14, _9, _6, _7 and _8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| _1| _3| _4| _5| _6| _7| _8| _9|_10|_12|_14|     _15|     _16|     _19|     _20|     _22|     _23|     _25|     _27|     _28|     _29|     _31|     _32|     _37|     _38|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|  0|  6|  3| 34|  4| 27|  3| 33| 34|  1| 15|05db9164|028bd518|25c83c98|fbad5c96|5b392875|a73ee510|4efc1873|f15f3681|b28479f6|9559bea6|07c540c4|2a40f0da|32c7478e|aee52b6f|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toy_df3 = toy_df2.drop('_17','_18','_21','_24','_26','_30','_35')\n",
    "tenK_df3 = tenK_df2.drop('_17','_18','_21','_24','_26','_30','_35')\n",
    "tenK_df3.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10758"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tenK_df3.cache()\n",
    "tenK_df3.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4: Binning of Categories**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From EDA we see that amongst remaining categorical features, unique category count for following  are very low.  \n",
    "_23, _20    \n",
    "For rest of the features we will try binning the categories into three distinct features. AT the same time converting the feature type to numerical.  \n",
    "Binning is done by checking frequency% count.  \n",
    "If frequency% > 50, value = 30  \n",
    "50> frequesncy >20, value = 20  \n",
    "Otherwise value = 10\n",
    "\n",
    "For null values populating one of the bin value randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check frequency of unique categories of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|_15     |count|\n",
      "+--------+-----+\n",
      "|7ceef477|5    |\n",
      "|decf6fa6|2    |\n",
      "+--------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## \"_15\" ##\n",
    "\n",
    "# From EDA we see that this feature has 188 unique categories and no missing values\n",
    "tenK_df3.groupBy(\"_15\").count().show(2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the unique category distribution will bin the values in three categories with below logic:  \n",
    "\n",
    "1. If value = '05db9164', new_value = 1  \n",
    "2. If value in ('8cf07265', '68fd1e64', '5a9ed9b0'), new_value = 2  \n",
    "3. For rest of the rows, new_value = 3  \n",
    "At the same time we will convert the column type to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate click through rate frequency count of each category, we will drop the rows with zero clicks\n",
    "\n",
    "#val output = df.where(\"col1>col2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"_16\" ##\n",
    "\n",
    "# From EDA we see that this feature has 406 unique categories and no missing values\n",
    "#tenK_df3.cube(\"_16\").count().show(406,False)\n",
    "\n",
    "#dm = tenK_df3.groupBy(\"_31\").count()\n",
    "# dm1 = tenK_df3.groupBy(\"_15\",\"_1\").count()\n",
    "# dm2 = tenK_df3.groupBy(\"_1\").count()\n",
    "#dm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.array(\n",
    "#     '10','20','30'\n",
    "#   ).getItem(\n",
    "#     (F.rand()*3)).cast(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: bigint, _3: bigint, _4: bigint, _5: bigint, _6: bigint, _7: bigint, _8: bigint, _9: bigint, _10: bigint, _12: bigint, _14: bigint, _15: int, _16: int, _19: int, _20: int, _22: int, _23: int, _25: int, _27: int, _28: int, _29: int, _31: int, _32: int, _37: int, _38: int, _15%: double, _16%: double, _19%: double, _22%: double, _25%: double, _27%: double, _28%: double, _29%: double, _31%: double, _32%: double, _37%: double, _38%: double]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Calculate frequency of unique category under each feature ########\n",
    "\n",
    "#exclude the list of features that are already binned with just few categories\n",
    "exclude_list = ['_23', '_20'] #, '_31'\n",
    "\n",
    "count = 0\n",
    "for i in tenK_df3.dtypes:\n",
    "    if i[1]=='string' and i[0] not in exclude_list:\n",
    "        feature = i[0]\n",
    "        cat_freq = tenK_df3.cube(feature).count()\n",
    "        cat_freqDF = cat_freq.withColumn('percent', ((col('count')/ 10758) * 100.0))\n",
    "        df1 = cat_freqDF.alias('df1')\n",
    "        if count== 0:\n",
    "            df2 = tenK_df3.alias('df2')\n",
    "        else:\n",
    "            df2 = tenK_freq_df.alias('df2')\n",
    "        \n",
    "        tenK_freq_df = df1.join(df2, df1[feature] == df2[feature]).select('df2.*',\n",
    "                                                                        df1['percent'].alias(feature+'%'))\n",
    "        \n",
    "        ###### Bin data into three categories based on the frequency percentage count.\n",
    "        # if frequency % of a category is greather/ equal to 50%, assigned value =30\n",
    "        # if frequency % of a category is greater than 19.99% but less than 50%, value = 20\n",
    "        # for the rest value is 10\n",
    "        tenK_freq_df = tenK_freq_df.withColumn(feature,\n",
    "        F.when(((tenK_freq_df[feature+'%'] > 50)|(tenK_freq_df[feature+'%'] == 50))\n",
    "           & (tenK_freq_df[feature] != ''),F.lit(30))\n",
    "        .otherwise(\n",
    "        F.when((tenK_freq_df[feature+'%'] < 50) & (tenK_freq_df[feature+'%'] > 19.99)\n",
    "           & (tenK_freq_df[feature] != ''),F.lit(20))\n",
    "        .otherwise(\n",
    "        F.when(tenK_freq_df[feature] == '', F.array(F.lit(10),F.lit(20),F.lit(30)).getItem((F.rand()*3).cast(\"int\")))\n",
    "        .otherwise(F.lit(10)))))\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    elif i[0] == '_23':\n",
    "        feature = '_23'\n",
    "        tenK_freq_df = tenK_freq_df.withColumn(feature,\n",
    "        F.when(tenK_freq_df[feature] == 'a73ee510', F.lit(30))\n",
    "        .otherwise(\n",
    "        F.when(tenK_freq_df[feature] == '7cc72ec2', F.lit(20))\n",
    "        .otherwise(\n",
    "        F.when(tenK_freq_df[feature] == '', F.array(F.lit(10),F.lit(20),F.lit(30)).getItem((F.rand()*3).cast(\"int\")))\n",
    "        .otherwise(F.lit(10)))))\n",
    "            \n",
    "    elif i[0] == '_20':\n",
    "        feature = '_20'    \n",
    "        tenK_freq_df = tenK_freq_df.withColumn(feature,\n",
    "        F.when(tenK_freq_df[feature] == '7e0ccccf', F.lit(30))\n",
    "        .otherwise(\n",
    "        F.when(tenK_freq_df[feature] == ('fbad5c96'), F.lit(20))\n",
    "        .otherwise(\n",
    "        F.when(tenK_freq_df[feature] == ('fe6b92e5'), F.lit(10))\n",
    "        .otherwise(\n",
    "        F.when(tenK_freq_df[feature] == '',\n",
    "                F.array(F.lit(10),F.lit(20),F.lit(30),F.lit(5)).getItem((F.rand()*4).cast(\"int\")))\n",
    "        .otherwise(F.lit(5))))))\n",
    "\n",
    "            \n",
    "tenK_freq_df.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenK_df4 = tenK_freq_df.drop('_15%','_16%','_19%','_22%','_25%','_27%','_28%','_29%', '_31%', '_32%', '_37%', '_38%')\n",
    "#tenK_df4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Replace null values in numerical variables with mean **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_mean(this_df):\n",
    "\n",
    "    '''\n",
    "    replace None value in Numerical variables with mean value\n",
    "    '''\n",
    "    stats = this_df.agg(*(avg(c).alias(c) for i,c in enumerate(this_df.columns) if i<11 and c != '_1'))\n",
    "    return this_df.na.fill(stats.first().asDict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenK_df5 = fill_with_mean(tenK_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+---+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "| _1| _3|  _4| _5|    _6| _7| _8| _9|_10|_12|_14|_15|_16|_19|_20|_22|_23|_25|_27|_28|_29|_31|_32|_37|_38|\n",
      "+---+---+----+---+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|  0|  6|   3| 34|     4| 27|  3| 33| 34|  1| 15| 30| 10| 30| 20| 10| 30| 10| 10| 20| 10| 10| 10| 20| 10|\n",
      "|  0|521|   1|  2|   512| 21|  3| 18| 44|  1|  2| 10| 10| 30|  5| 30| 30| 10| 10| 20| 10| 20| 10| 10| 10|\n",
      "|  1|  0|   1|  1|  4982|111|  0|  1| 10|  0|  1| 10| 10| 10| 20| 30| 30| 10| 10| 20| 10| 10| 10| 10| 10|\n",
      "|  0|156|  75| 15|  1352|276|  2| 49|104|  1| 50| 30| 10| 30| 30| 10| 30| 10| 10| 20| 10| 10| 10| 20| 10|\n",
      "|  1|  0|  12| 12|     1|  0| 16| 12| 81|  5|  0| 10| 10| 10|  5| 30| 30| 10| 10| 20| 10| 20| 10| 20| 10|\n",
      "|  1|  0|  16|  7|  7263| 51|  5|  8|132|  3|  7| 30| 10| 30| 10| 30| 30| 10| 10| 20| 10| 20| 10| 10| 10|\n",
      "|  0|  0|   1|  8|     0|  0|  2|  2|  1|  1|  0| 30| 10| 30| 30| 30| 30| 10| 10| 20| 10| 20| 10| 20| 10|\n",
      "|  0|  0|  75| 18|    15| 63|  1| 18| 18|  1| 18| 10| 10| 30| 20| 30| 30| 10| 10| 20| 10| 10| 10| 20| 10|\n",
      "|  0| -1|   0|  7| 18550|111| 15|  0|104|  2|  8| 10| 10| 10| 20| 10| 20| 10| 10| 20| 10| 10| 10| 10| 10|\n",
      "|  1| -1|   2| 12|    44| 12|  5|  5| 13|  2| 12| 10| 10| 30| 30| 10| 30| 10| 10| 10| 10| 10| 10| 10| 10|\n",
      "|  0| 47|   8|  8| 27987|360|  2|  8|209|  1|  8| 30| 10| 30| 30| 30| 30| 10| 10| 20| 10| 10| 10| 20| 10|\n",
      "|  0| 28| 112|  2| 18699|111|  0|  2|  1|  0|  2| 10| 10| 10| 30| 30| 30| 10| 10| 20| 10| 10| 10| 10| 10|\n",
      "|  1|208|1340|  3|    17|  0|  2| 49|  9|  1|  0| 30| 10| 30| 20| 30| 30| 10| 10| 20| 10| 20| 10| 20| 10|\n",
      "|  0| 61|   4|  6| 18550|111|  0|  4|  6|  0|  6| 30| 10| 30| 30| 30| 20| 10| 10| 20| 10| 10| 10| 10| 10|\n",
      "|  1|  0|   9| 10|     1| 10|  2| 13| 10|  1|  7| 30| 10| 10|  5| 30| 30| 10| 10| 20| 10| 10| 10| 20| 10|\n",
      "|  0|  0|  15| 20|    47| 20|  1| 21| 49|  1| 20| 10| 10| 30| 30| 30| 30| 10| 10| 10| 10| 20| 10| 10| 10|\n",
      "|  0|  0|  58|  2|     5|  2|  8|  1|  2|  1|  2| 30| 10| 30|  5| 30| 30| 10| 10| 20| 10| 20| 10| 20| 10|\n",
      "|  0|  2|  33|  4|  5754| 32| 21|  4|184|  4|  4| 10| 10| 30| 30| 30| 30| 10| 10| 20| 10| 20| 10| 10| 10|\n",
      "|  1|  0|   8|  5|155916|111|  0|  5| 14|  0|  5| 30| 10| 30| 30| 10| 20| 10| 10| 20| 10| 10| 10| 20| 10|\n",
      "|  1| -1|  33|  7|  4472| 78| 15|  0|  2|  2|  8| 30| 10| 10| 30| 30| 30| 10| 10| 20| 10| 10| 10| 20| 10|\n",
      "+---+---+----+---+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tenK_df5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is rough version of RandomForest Classifier. Do not look at this ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "toyFeature_df = sqlContext.createDataFrame(toyRDD)\n",
    "toy_df = toyFeature_df.drop('_13','_36','_2','_11','_33','_34','_39','_40')\n",
    "toyDF = fill_with_mean(toy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6: Run RandomForest ensemble to check featureImportances**:  \n",
    "With remaining features we will run RandomForest ensemble classifier to check featureImportances matrices.  \n",
    "We will extract the Features with higher featureImportances scores for our model.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# one hot encoding and assembling\n",
    "\n",
    "encoding_var = [i[0] for i in toyDF.dtypes if (i[1]=='string')]\n",
    "num_var = [i[0] for i in toyDF.dtypes if (i[1]!='string') & (i[0]!= '_1')]\n",
    "#encoding_var = [col for i, col in enumerate(toyDF.columns) if (i > 0) & (i<11)]\n",
    "#num_var = [col for j, col in enumerate(toyDF.columns) if (j > 14)]\n",
    "\n",
    "string_indexes = [StringIndexer(inputCol = c, outputCol = 'IDX_' + c, handleInvalid = 'keep')\n",
    "                  for c in encoding_var]\n",
    "onehot_indexes = [OneHotEncoderEstimator(inputCols = ['IDX_' + c], outputCols = ['OHE_' + c])\n",
    "                  for c in encoding_var]\n",
    "label_indexes = StringIndexer(inputCol = '_1', outputCol = 'label', handleInvalid = 'keep')\n",
    "assembler = VectorAssembler(inputCols = num_var + ['OHE_' + c for c in encoding_var]\n",
    "                            , outputCol = \"features\")\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed = 8464,\n",
    "                             numTrees=10, cacheNodeIds = True, subsamplingRate = 0.7)\n",
    "\n",
    "pipe = Pipeline(stages = string_indexes + onehot_indexes + [assembler, label_indexes, rf])\n",
    "#num_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = pipe.fit(toyDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyDF2 = mod.transform(toyDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(1182, {3: 0.0042, 6: 0.0272, 7: 0.0466, 10: 0.0033, 12: 0.01, 20: 0.021, 23: 0.009, 47: 0.0329, 53: 0.0145, 91: 0.013, 99: 0.0275, 114: 0.0278, 137: 0.0145, 142: 0.0066, 172: 0.0101, 200: 0.0119, 212: 0.0249, 213: 0.0145, 219: 0.0131, 258: 0.0198, 267: 0.0253, 272: 0.0194, 368: 0.0004, 389: 0.0355, 398: 0.0, 435: 0.009, 445: 0.0204, 450: 0.0124, 469: 0.0086, 476: 0.033, 493: 0.0, 574: 0.0229, 577: 0.023, 578: 0.0184, 598: 0.0198, 608: 0.0063, 719: 0.0203, 758: 0.0079, 789: 0.0088, 803: 0.0112, 833: 0.0086, 855: 0.0217, 866: 0.0257, 897: 0.0127, 903: 0.0227, 952: 0.0194, 962: 0.0139, 994: 0.0252, 1000: 0.0085, 1033: 0.0068, 1034: 0.0272, 1047: 0.0137, 1052: 0.0462, 1053: 0.0234, 1083: 0.0073, 1102: 0.0377, 1103: 0.0004, 1106: 0.0113, 1141: 0.0123})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.stages[-1].featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeatureImp(featureImp, dataset, featuresCol):\n",
    "    list_extract = []\n",
    "    for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
    "    return(varlist.sort_values('score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>_10</td>\n",
       "      <td>0.046568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>1052</td>\n",
       "      <td>OHE__35_0d3fb920</td>\n",
       "      <td>0.046160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>1102</td>\n",
       "      <td>OHE__37_32c7478e</td>\n",
       "      <td>0.037704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>389</td>\n",
       "      <td>OHE__24_67eea4ef</td>\n",
       "      <td>0.035513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>476</td>\n",
       "      <td>OHE__25_59256bd8</td>\n",
       "      <td>0.033034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>OHE__16_2705da39</td>\n",
       "      <td>0.032902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>OHE__17_73cee255</td>\n",
       "      <td>0.027846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>OHE__17_3cc14b5b</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>1034</td>\n",
       "      <td>OHE__35_d8126a6f</td>\n",
       "      <td>0.027239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>_9</td>\n",
       "      <td>0.027237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>866</td>\n",
       "      <td>OHE__30_0f0c3616</td>\n",
       "      <td>0.025726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>267</td>\n",
       "      <td>OHE__19_30903e74</td>\n",
       "      <td>0.025279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994</td>\n",
       "      <td>OHE__32_13145934</td>\n",
       "      <td>0.025180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>212</td>\n",
       "      <td>OHE__18_8bcf4b56</td>\n",
       "      <td>0.024921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1053</td>\n",
       "      <td>OHE__35_8fdaeac7</td>\n",
       "      <td>0.023370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>577</td>\n",
       "      <td>OHE__26_1ca7a526</td>\n",
       "      <td>0.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>574</td>\n",
       "      <td>OHE__26_0f52da65</td>\n",
       "      <td>0.022887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>903</td>\n",
       "      <td>OHE__30_8659f9bb</td>\n",
       "      <td>0.022704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>855</td>\n",
       "      <td>OHE__30_ba46c3a1</td>\n",
       "      <td>0.021734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>OHE__15_ae82ea21</td>\n",
       "      <td>0.020996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>445</td>\n",
       "      <td>OHE__24_441dd290</td>\n",
       "      <td>0.020354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>719</td>\n",
       "      <td>OHE__27_499d401f</td>\n",
       "      <td>0.020344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>258</td>\n",
       "      <td>OHE__18_26ac5cc6</td>\n",
       "      <td>0.019840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>598</td>\n",
       "      <td>OHE__26_80569ec1</td>\n",
       "      <td>0.019811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>OHE__20_fe6b92e5</td>\n",
       "      <td>0.019430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>952</td>\n",
       "      <td>OHE__32_97029569</td>\n",
       "      <td>0.019411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>578</td>\n",
       "      <td>OHE__26_dce1c382</td>\n",
       "      <td>0.018370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>213</td>\n",
       "      <td>OHE__18_b5f12c03</td>\n",
       "      <td>0.014527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>OHE__16_bccb7a1a</td>\n",
       "      <td>0.014505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>OHE__17_8781d7d8</td>\n",
       "      <td>0.014467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>OHE__24_49d1ad89</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>OHE__24_2436c534</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>394</td>\n",
       "      <td>OHE__24_6a5d2b37</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>393</td>\n",
       "      <td>OHE__24_93aa528a</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>391</td>\n",
       "      <td>OHE__24_70726fe6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>417</td>\n",
       "      <td>OHE__24_18139a78</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>390</td>\n",
       "      <td>OHE__24_b93f1fe6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>388</td>\n",
       "      <td>OHE__24_42635bfd</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>387</td>\n",
       "      <td>OHE__24_a5bb26cf</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>386</td>\n",
       "      <td>OHE__24_31990058</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>385</td>\n",
       "      <td>OHE__24_9268adb2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>384</td>\n",
       "      <td>OHE__24_efea433b</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>OHE__24_80254878</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401</td>\n",
       "      <td>OHE__24_8d34ddcd</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>402</td>\n",
       "      <td>OHE__24_691fab4c</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>403</td>\n",
       "      <td>OHE__24_8abe1ec6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>404</td>\n",
       "      <td>OHE__24_30819844</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>OHE__24_0f1a2599</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>OHE__24_753998f6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>OHE__24_060196aa</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>408</td>\n",
       "      <td>OHE__24_b9c8f9a2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>OHE__24_099b68bd</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>OHE__24_aa1b82d3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>411</td>\n",
       "      <td>OHE__24_f3b83678</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>412</td>\n",
       "      <td>OHE__24_fbbf2c95</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>413</td>\n",
       "      <td>OHE__24_27fdd7aa</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>414</td>\n",
       "      <td>OHE__24_49105239</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>415</td>\n",
       "      <td>OHE__24_f364a867</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>416</td>\n",
       "      <td>OHE__24_ba06e67a</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>1181</td>\n",
       "      <td>OHE__38_ebf21959</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1182 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx              name     score\n",
       "7        7               _10  0.046568\n",
       "1052  1052  OHE__35_0d3fb920  0.046160\n",
       "1102  1102  OHE__37_32c7478e  0.037704\n",
       "389    389  OHE__24_67eea4ef  0.035513\n",
       "476    476  OHE__25_59256bd8  0.033034\n",
       "47      47  OHE__16_2705da39  0.032902\n",
       "114    114  OHE__17_73cee255  0.027846\n",
       "99      99  OHE__17_3cc14b5b  0.027500\n",
       "1034  1034  OHE__35_d8126a6f  0.027239\n",
       "6        6                _9  0.027237\n",
       "866    866  OHE__30_0f0c3616  0.025726\n",
       "267    267  OHE__19_30903e74  0.025279\n",
       "994    994  OHE__32_13145934  0.025180\n",
       "212    212  OHE__18_8bcf4b56  0.024921\n",
       "1053  1053  OHE__35_8fdaeac7  0.023370\n",
       "577    577  OHE__26_1ca7a526  0.023000\n",
       "574    574  OHE__26_0f52da65  0.022887\n",
       "903    903  OHE__30_8659f9bb  0.022704\n",
       "855    855  OHE__30_ba46c3a1  0.021734\n",
       "20      20  OHE__15_ae82ea21  0.020996\n",
       "445    445  OHE__24_441dd290  0.020354\n",
       "719    719  OHE__27_499d401f  0.020344\n",
       "258    258  OHE__18_26ac5cc6  0.019840\n",
       "598    598  OHE__26_80569ec1  0.019811\n",
       "272    272  OHE__20_fe6b92e5  0.019430\n",
       "952    952  OHE__32_97029569  0.019411\n",
       "578    578  OHE__26_dce1c382  0.018370\n",
       "213    213  OHE__18_b5f12c03  0.014527\n",
       "53      53  OHE__16_bccb7a1a  0.014505\n",
       "137    137  OHE__17_8781d7d8  0.014467\n",
       "...    ...               ...       ...\n",
       "396    396  OHE__24_49d1ad89  0.000000\n",
       "395    395  OHE__24_2436c534  0.000000\n",
       "394    394  OHE__24_6a5d2b37  0.000000\n",
       "393    393  OHE__24_93aa528a  0.000000\n",
       "391    391  OHE__24_70726fe6  0.000000\n",
       "417    417  OHE__24_18139a78  0.000000\n",
       "390    390  OHE__24_b93f1fe6  0.000000\n",
       "388    388  OHE__24_42635bfd  0.000000\n",
       "387    387  OHE__24_a5bb26cf  0.000000\n",
       "386    386  OHE__24_31990058  0.000000\n",
       "385    385  OHE__24_9268adb2  0.000000\n",
       "384    384  OHE__24_efea433b  0.000000\n",
       "400    400  OHE__24_80254878  0.000000\n",
       "401    401  OHE__24_8d34ddcd  0.000000\n",
       "402    402  OHE__24_691fab4c  0.000000\n",
       "403    403  OHE__24_8abe1ec6  0.000000\n",
       "404    404  OHE__24_30819844  0.000000\n",
       "405    405  OHE__24_0f1a2599  0.000000\n",
       "406    406  OHE__24_753998f6  0.000000\n",
       "407    407  OHE__24_060196aa  0.000000\n",
       "408    408  OHE__24_b9c8f9a2  0.000000\n",
       "409    409  OHE__24_099b68bd  0.000000\n",
       "410    410  OHE__24_aa1b82d3  0.000000\n",
       "411    411  OHE__24_f3b83678  0.000000\n",
       "412    412  OHE__24_fbbf2c95  0.000000\n",
       "413    413  OHE__24_27fdd7aa  0.000000\n",
       "414    414  OHE__24_49105239  0.000000\n",
       "415    415  OHE__24_f364a867  0.000000\n",
       "416    416  OHE__24_ba06e67a  0.000000\n",
       "1181  1181  OHE__38_ebf21959  0.000000\n",
       "\n",
       "[1182 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtractFeatureImp(mod.stages[-1].featureImportances, toyDF2, \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| _2| _3| _4| _5|   _6| _7| _8| _9|_10|_11|_12|_13|_14|     _15|     _16|     _17|     _18|     _19|     _20|     _21|     _22|     _23|     _23|     _24|     _25|     _26|     _27|     _28|     _29|     _30|     _31|     _32|     _33|     _34|     _35|     _36|     _37|     _38|     _39|     _40|\n",
      "+---+---+---+---+-----+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| ''| -1| ''| ''|23106| 90|  8| 32|103| ''|  2| ''| ''|68fd1e64|d833535f|b00d1501|d16679b9|25c83c98|fe6b92e5|e30c82b2|51d76abe|a73ee510|a73ee510|7471f41c|9bd51b96|e0d76380|18539b7f|b28479f6|a733d362|1203a270|e5ba7672|281769c2|      ''|      ''|73d06dde|      ''|3a171ecb|aee52b6f|      ''|      ''|\n",
      "| ''| 17|  4|  1|11391|284|  2|  1|374| ''|  2| ''|  1|68fd1e64|38a947a1|      ''|      ''|25c83c98|7e0ccccf|5ce4765a|0b153874|a73ee510|a73ee510|f0405fd0|c1dcf5cb|      ''|bccc0f27|07d13a8f|cfd71361|      ''|e5ba7672|8f6ce7c7|      ''|      ''|      ''|ad3062eb|32c7478e|      ''|      ''|      ''|\n",
      "| ''| 41|  5|  1| 8674| 14|  1|  2| 14| ''|  1| ''|  1|05db9164|a07503cc|5300bdf3|13508380|25c83c98|fbad5c96|05940d6c|0b153874|a73ee510|a73ee510|3b08e48b|59256bd8|0f52da65|679527fa|07d13a8f|77660bba|cdf08556|d4bb7bd8|912c7e21|55dd3565|b1252a9d|47869145|      ''|32c7478e|45ab94c8|445bbe3b|c84c4aec|\n",
      "| ''| -1| ''| ''| 5762|  1|  1|  0|  0| ''|  1| ''| ''|05db9164|2705da39|64e7c756|8bcf4b56|25c83c98|7e0ccccf|0dbf2675|0b153874|a73ee510|a73ee510|753998f6|88196a93|7b559283|1211c647|07d13a8f|74056b5a|6a473526|e5ba7672|66c3058a|      ''|      ''|36697b7d|      ''|32c7478e|043ce596|      ''|      ''|\n",
      "|  2| 19|  9| 42|    4| 34|  2| 49| 39|  1|  1| ''| 16|68fd1e64|38d50e09|337faecd|4bfdb1a0|25c83c98|fbad5c96|9b98e9fc|0b153874|a73ee510|a73ee510|441dd290|7f8ffe57|8413bdc0|46f42a63|b28479f6|42b3012c|4693efe3|e5ba7672|582152eb|21ddcdc9|5840adea|4489087f|ad3062eb|32c7478e|29383373|001f3601|4e7af834|\n",
      "+---+---+---+---+-----+---+---+---+---+---+---+---+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df = spark.createDataFrame([\n",
    "#      (1.0, Vectors.dense(1.0)),\n",
    "#      (0.0, Vectors.sparse(1, [], []))], [\"label\", \"features\"])\n",
    "\n",
    "# stringIndexer = StringIndexer(inputCol=\"_1\", outputCol=\"indexed\")\n",
    "# si_model = stringIndexer.fit(toyFeature_df)\n",
    "# td = si_model.transform(toyFeature_df)\n",
    "# rf = RandomForestClassifier(numTrees=3, maxDepth=2, labelCol=\"indexed\", seed=42)\n",
    "# model = rf.fit(td)\n",
    "# model.featureImportances\n",
    "# SparseVector(1, {0: 1.0})\n",
    "\n",
    "X = toyFeature_df.select(\"_2\", \"_3\", \"_4\", \"_5\", \"_6\", \"_7\", \"_8\", \"_9\", \"_10\", \"_11\", \"_12\", \"_13\"\n",
    "                         , \"_14\", \"_15\", \"_16\", \"_17\", \"_18\", \"_19\", \"_20\", \"_21\", \"_22\", \"_23\", \"_23\"\n",
    "                         , \"_24\", \"_25\", \"_26\", \"_27\", \"_28\", \"_29\", \"_30\", \"_31\", \"_32\", \"_33\", \"_34\"\n",
    "                         , \"_35\", \"_36\", \"_37\", \"_38\", \"_39\", \"_40\")\n",
    "y = toyFeature_df.select(\"_1\")\n",
    "\n",
    "# clf = RandomForestClassifier(numTrees=3, maxDepth=2, labelCol=\"indexed\", seed=42)\n",
    "\n",
    "# clf.fit(X, y)  \n",
    "#print(clf.feature_importances_)\n",
    "\n",
    "X.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Field \"features\" does not exist.\\nAvailable fields: _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17, _18, _19, _20, _21, _22, _23, _24, _25, _26, _27, _28, _29, _30, _31, _32, _33, _34, _35, _36, _37, _38, _39, _40, indexed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1113.fit.\n: java.lang.IllegalArgumentException: Field \"features\" does not exist.\nAvailable fields: _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17, _18, _19, _20, _21, _22, _23, _24, _25, _26, _27, _28, _29, _30, _31, _32, _33, _34, _35, _36, _37, _38, _39, _40, indexed\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:267)\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:267)\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:266)\n\tat org.apache.spark.ml.util.SchemaUtils$.checkColumnType(SchemaUtils.scala:40)\n\tat org.apache.spark.ml.PredictorParams$class.validateAndTransformSchema(Predictor.scala:51)\n\tat org.apache.spark.ml.classification.Classifier.org$apache$spark$ml$classification$ClassifierParams$$super$validateAndTransformSchema(Classifier.scala:58)\n\tat org.apache.spark.ml.classification.ClassifierParams$class.validateAndTransformSchema(Classifier.scala:42)\n\tat org.apache.spark.ml.classification.ProbabilisticClassifier.org$apache$spark$ml$classification$ProbabilisticClassifierParams$$super$validateAndTransformSchema(ProbabilisticClassifier.scala:53)\n\tat org.apache.spark.ml.classification.ProbabilisticClassifierParams$class.validateAndTransformSchema(ProbabilisticClassifier.scala:37)\n\tat org.apache.spark.ml.classification.ProbabilisticClassifier.validateAndTransformSchema(ProbabilisticClassifier.scala:53)\n\tat org.apache.spark.ml.Predictor.transformSchema(Predictor.scala:144)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:100)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-6e04818dbcf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumTrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxDepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"indexed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Field \"features\" does not exist.\\nAvailable fields: _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17, _18, _19, _20, _21, _22, _23, _24, _25, _26, _27, _28, _29, _30, _31, _32, _33, _34, _35, _36, _37, _38, _39, _40, indexed'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
